{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a568ac01",
   "metadata": {},
   "source": [
    "# K-Visitation analysis and distribution of $q_K$\n",
    "\n",
    "**Description:**\n",
    "This notebook reproduces Figure 2 and 3 in the manuscript.\n",
    "1. **Figure 2a:** KDE distribution of alignment coefficients across cities.\n",
    "2. **Figure 2b:** Comparison of $q_K$ between empirical data, no work scenario and null scenario.\n",
    "3. **Figure 2c-d:** Comparison of experience segregation and POI diversity between $K_{freq}$ and $K_{dist}$ across the three scenarios.\n",
    "4. **Figure 3:** Spatial mapping of $q_K$ in Helsinki, Tampere, Turku and Oulu regions.\n",
    "\n",
    "**Data Source:** \n",
    "- `data/qk_grid.csv`: Aggregated grid-level metrics (Provided in repo).\n",
    "- `data/poi_seg_diff.csv`: Aggregated grid-level POI diversity and segregation differences (Provided in repo).\n",
    "- `data/finn_1km_grid.parquet`: Grid spatial data (Provided in repo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03efc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "from pypalettes import load_cmap\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "from shapely.affinity import scale\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "# Setup project root path\n",
    "project_root = Path.cwd()\n",
    "if 'notebooks' in str(project_root):\n",
    "    project_root = project_root.parent\n",
    "\n",
    "# Add src to path\n",
    "src_path = str(project_root / 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Set data path\n",
    "data_dir = project_root / 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa6381",
   "metadata": {},
   "source": [
    "## Demo: Calculate K-visitation and local alignment $q_K$  for users\n",
    "Below we include the code to calculate K-visitations for each user and their alignment coefficient $q_K$. \n",
    "For privacy issues, this is only for demonstration purposes with anonymised sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85843fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_visitation import calculate_both_k_places, calculate_qk_alignment\n",
    "\n",
    "# Load data\n",
    "# The data containing user visitations, for testing purposes we use a sample anonymised data\n",
    "data_path = data_dir / 'sample_anonymised_data.csv'\n",
    "\n",
    "if data_path.exists():\n",
    "    print(f\"Loading data from {data_path}...\")\n",
    "    stay_locations = pd.read_csv(data_path)\n",
    "    \n",
    "else:\n",
    "    print(f\"Data file not found at {data_path}. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "amenity_list = [\n",
    "    'CIVIC_RELIGION', 'CULTURE', 'DINING', 'EDUCATION', 'FITNESS', \n",
    "    'GROCERIES', 'HEALTHCARE', 'RETAIL', 'SERVICE', 'TRANSPORT'\n",
    "]\n",
    "\n",
    "smallest_values = np.ones(len(amenity_list), dtype=int)\n",
    "\n",
    "# Calculate K-freq and K-dist for all users\n",
    "places_k = calculate_both_k_places(stay_locations, amenity_list, smallest_values)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate qK alignment\n",
    "user_qk = calculate_qk_alignment(\n",
    "    places_df=places_k,\n",
    "    user_col='user_id', \n",
    "    k_freq_col='k_freq',\n",
    "    k_dist_col='k_dist'\n",
    ")\n",
    "\n",
    "print(user_qk.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81501cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section aggregate user-level data to 1km grid level. For privacy concerns, the next cell is only shown to illustrate the aggregation process. \n",
    "\n",
    "\n",
    "# qk_grid = user_qk.groupby('home_grd_id').agg({\n",
    "#     'user_id':'size',\n",
    "#     'qk':'mean',\n",
    "#     }\n",
    "# ).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a002795",
   "metadata": {},
   "source": [
    "## Aggregated grid-level data\n",
    "Figures 2 and 3 can be reproduced from the main manuscript using pre-aggregated grid-level data for privacy compliance.\n",
    "\n",
    "The loaded data contains following attributes:\n",
    "- `grd_id`: 1km Finland official grid cell ID, each user is aggregated based on their the grid id their home location belonged to.\n",
    "- `n_users`: Number of users we obtained in the grid cell.\n",
    "- `popu`: Population in the grid cell, obtained from census data.\n",
    "- `mean_qk`: Mean alignment coefficient of users in the grid cell.\n",
    "- `mean_qk_nw`: Mean alignment coefficient of users in the grid cell excluding work-related trips.\n",
    "- `mean_qk_null`: Mean alignment coefficient of users in the grid cell from null model (d-EPR model, see Methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae68e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "qk_grid = pd.read_csv(data_dir / 'qk_grid.csv')\n",
    "qk_grid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03440d76",
   "metadata": {},
   "source": [
    "##  Fig 2a. KDE distribution of alignment coefficients across cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Visualisation: Figure 2a. KDE plots of qK distributions across cities\n",
    "\n",
    "\n",
    "\n",
    "# Ten largest cities in Finland by population\n",
    "cities = ['Helsinki', \n",
    "          'Espoo',\n",
    "          'Kauniainen',\n",
    "          'Vantaa',\n",
    "          # Above is the helsinki region\n",
    "          'Tampere', \n",
    "          'Oulu', \n",
    "          'Turku',\n",
    "          'Jyväskylä', \n",
    "          'Kuopio', \n",
    "          'Lahti', \n",
    "          'Pori', \n",
    "          'Lappeenranta',\n",
    "            'Vaasa',\n",
    "            'Kotka',\n",
    "            'Joensuu',\n",
    "          ]\n",
    "\n",
    "# Filter data\n",
    "grid_filtered = qk_grid[qk_grid['n_users'] > 5] \n",
    "grid_cities = grid_filtered[grid_filtered['city'].isin(cities)].copy()\n",
    "\n",
    "# Calculate mean qk for each city and assign to each row\n",
    "city_means = grid_cities.groupby('city')['mean_qk'].mean()\n",
    "grid_cities['mean_qk_city'] = grid_cities['city'].map(city_means)\n",
    "# Calculate top 3 most populated grids for each city\n",
    "top_by_city = {}\n",
    "for city in cities:\n",
    "    city_data = grid_cities[grid_cities['city'] == city]\n",
    "    if len(city_data) > 0:\n",
    "        top = city_data.nlargest(2, 'popu')\n",
    "        # Calculate mean qk for top 2 grids\n",
    "        top_mean = top['mean_qk'].mean()\n",
    "        top_by_city[city] = top_mean\n",
    "\n",
    "\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "base = load_cmap('miami2')\n",
    "anchor_colors = base.colors\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    'miami2_continuous',\n",
    "    anchor_colors,\n",
    "    N=256\n",
    ")\n",
    "\n",
    "\n",
    "city_means = grid_cities.groupby('city')['mean_qk'].mean()\n",
    "norm = mpl.colors.Normalize(city_means.min(), city_means.max())\n",
    "color_mapping = {city: cmap(norm(m)) for city, m in city_means.items()}\n",
    "pal = [color_mapping[city] for city in cities]\n",
    "\n",
    "\n",
    "g = sns.FacetGrid(grid_cities, row='city', aspect=10, height=0.6, palette=pal, row_order=cities)\n",
    "\n",
    "g.figure.set_dpi(100)\n",
    "\n",
    "# Add the densities kdeplots for each city with colored fills\n",
    "g.map(sns.kdeplot, 'mean_qk',\n",
    "      bw_adjust=0.9, clip=(0, 1),\n",
    "      color='w',\n",
    "      fill=True, alpha=0.8, linewidth=0)\n",
    "\n",
    "# Add colored outline for each kdeplot\n",
    "for idx, (ax, city) in enumerate(zip(g.axes.flat, cities)):\n",
    "      if idx < len(cities):\n",
    "            city_data = grid_cities[grid_cities['city'] == city]['mean_qk'].dropna()\n",
    "            if len(city_data) > 0:\n",
    "                  sns.kdeplot(data=city_data, ax=ax, bw_adjust=0.9, clip=(0, 1), \n",
    "                            color=color_mapping[city], lw=4, fill=False)\n",
    "\n",
    "# Add horizontal line for each plot\n",
    "g.map(plt.axhline, y=0, color='grey', alpha=0.5, lw=2, clip_on=False)\n",
    "\n",
    "# Get subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-0.3)\n",
    "\n",
    "# Add vertical lines at city means with height matching KDE and city names\n",
    "for idx, ax in enumerate(g.axes.flat):\n",
    "      if idx < len(cities):\n",
    "            city = cities[idx]\n",
    "            city_data = grid_cities[grid_cities['city'] == city]['mean_qk'].dropna()\n",
    "            if len(city_data) > 0:\n",
    "                  mean = city_data.mean()\n",
    "                  \n",
    "                  # Get the KDE line data from the plot\n",
    "                  kdeline = ax.lines[0]\n",
    "                  xs = kdeline.get_xdata()\n",
    "                  ys = kdeline.get_ydata()\n",
    "                  \n",
    "                  # Interpolate to find height at mean\n",
    "                  height = np.interp(mean, xs, ys)\n",
    "                  \n",
    "                  # Draw vertical line at mean\n",
    "                  ax.vlines(mean, 0, height, color='k', ls='-', linewidth=1.5, zorder=10)\n",
    "\n",
    "                  # Add city name on the left side\n",
    "                  ax.text(-0.05, 0.4, city, transform=ax.transAxes, \n",
    "                              fontsize=12, va='center', ha='right')\n",
    "                  \n",
    "                  # Make subplot background transparent\n",
    "                  ax.patch.set_alpha(0)\n",
    "                  plt.setp(ax.get_xticklabels(), visible=True, fontsize=11)\n",
    "\n",
    "# Plot top 2 most populated grids as a single dot\n",
    "for idx, ax in enumerate(g.axes.flat):\n",
    "      if idx < len(cities):\n",
    "            city = cities[idx]\n",
    "            if city in top_by_city:\n",
    "                  top_qk = top_by_city[city]\n",
    "                  ylim = ax.get_ylim()\n",
    "                  # Get KDE line for this subplot to find y position at top3_qk\n",
    "                  kdeline = ax.lines[0]\n",
    "                  xs_kde = kdeline.get_xdata()\n",
    "                  ys_kde = kdeline.get_ydata()\n",
    "                  y_offset = np.interp(top_qk, xs_kde, ys_kde)\n",
    "                  ax.scatter(top_qk, y_offset, color='#333333', s=100, \n",
    "                           edgecolor='white', linewidth=2, zorder=100, marker='o', clip_on=False, alpha=0.9)\n",
    "\n",
    "# Make figure background transparent\n",
    "g.figure.patch.set_alpha(0)\n",
    "\n",
    "# Remove axes titles, yticks and spines\n",
    "g.set_titles(\"\")\n",
    "g.set_ylabels('')\n",
    "g.set(xticks=[0, 0.25, 0.5, 0.75, 1.0])\n",
    "g.set(yticks=[])\n",
    "g.despine(bottom=True, left=True)\n",
    "\n",
    "plt.xlabel('$q_K$', fontsize=12)\n",
    "\n",
    "# g.savefig('figures/qk-distribution.svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Visualisation: Custom gradient colormap for Fig 2a\n",
    "\n",
    "\n",
    "# Recreate the custom gradient colormap\n",
    "# Sample colors from the colormap\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, 5)]\n",
    "\n",
    "# Create custom colormap from these colors\n",
    "n_bins = 256\n",
    "custom_cmap = LinearSegmentedColormap.from_list('custom_gradient', colors, N=n_bins)\n",
    "\n",
    "# Create figure with colorbar\n",
    "fig, ax = plt.subplots(figsize=(6, 1.1))\n",
    "\n",
    "# Create a normalization based on the qK range\n",
    "norm = Normalize(vmin=0.6, vmax=0.7)\n",
    "\n",
    "# Create colorbar\n",
    "cb = ColorbarBase(ax, cmap=custom_cmap, norm=norm, orientation='horizontal')\n",
    "cb.set_label('Mean $q_K$ by City', fontsize=12)\n",
    "cb.set_ticks([0.6, 0.65, 0.7])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('figures/qk-cmap.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153ac4a",
   "metadata": {},
   "source": [
    "## Fig 2b. Comparison with the null model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e747c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter grids with more than 5 users to minimise noise\n",
    "grid_filtered = qk_grid[qk_grid['n_users'] > 5]\n",
    "\n",
    "# Define city groups\n",
    "helsinki_region = ['Helsinki', 'Espoo', 'Kauniainen', 'Vantaa']\n",
    "helsinki = grid_filtered[grid_filtered['city'].isin(helsinki_region)]\n",
    "other_cities = grid_filtered[~grid_filtered['city'].isin(helsinki_region)]\n",
    "\n",
    "# Prepare data for plotting\n",
    "groups = [helsinki, other_cities]\n",
    "group_names = ['Helsinki region', 'Finland']\n",
    "\n",
    "# Metrics\n",
    "metric_names = ['$Normal$', '$Excl. work$', '$Null$']\n",
    "metric_cols  = ['mean_qk', 'mean_qk_nw', 'mean_qk_null']\n",
    "\n",
    "metric_colors = ['#1B8B8B', '#E74C3C', '#F39C12']\n",
    "metric_markers = ['o', 's', '^']\n",
    "\n",
    "group_gap = 0.35\n",
    "metric_step = 0.28\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "# Collect data for scatter plot\n",
    "scatter_points = []\n",
    "\n",
    "# Violin plot data\n",
    "# violin_data = []\n",
    "# violin_positions = []\n",
    "# violin_colors = []\n",
    "\n",
    "x_position = 0\n",
    "x_labels = []\n",
    "x_label_positions = []\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "for group_idx, (data_group, group_name) in enumerate(zip(groups, group_names)):\n",
    "    group_start = x_position\n",
    "\n",
    "    for metric_idx, (metric_col, metric_name, marker, color) in enumerate(\n",
    "        zip(metric_cols, metric_names, metric_markers, metric_colors)\n",
    "    ):\n",
    "        data = data_group[metric_col].dropna()\n",
    "\n",
    "        if len(data) > 0:\n",
    "            # Sample 10% of the data for scatter plot\n",
    "            sample_size = max(1, int(len(data) * 0.2))\n",
    "            sampled_indices = np.random.choice(len(data), size=sample_size, replace=False)\n",
    "            sampled_data = data.iloc[sampled_indices].values\n",
    "            \n",
    "            # Calculate density-based jitter width\n",
    "            # Estimate KDE at each sampled point\n",
    "            try:\n",
    "                kde = gaussian_kde(data.values)\n",
    "                densities = kde(sampled_data)\n",
    "                # Normalize densities to create jitter width (higher density = wider spread)\n",
    "                density_normalized = densities / densities.max()\n",
    "                max_jitter = 0.05  # Maximum jitter width\n",
    "                jitter_widths = density_normalized * max_jitter\n",
    "            except:\n",
    "                # Fallback if KDE fails\n",
    "                jitter_widths = np.full(sample_size, 0.02)\n",
    "            \n",
    "            # Create jitter positions with density-aware spreading\n",
    "            jitter_x = np.array([np.random.normal(x_position, jw) for jw in jitter_widths])\n",
    "            \n",
    "            # Store scatter data\n",
    "            scatter_points.append({\n",
    "                'x': jitter_x,\n",
    "                'y': sampled_data,\n",
    "                'color': color,\n",
    "                'alpha': 0.2\n",
    "            })\n",
    "            \n",
    "            # # Add violin plot data\n",
    "            # p10_val = data.quantile(0.10)\n",
    "            # p90_val = data.quantile(0.90)\n",
    "            # data_filtered = data[(data >= p10_val) & (data <= p90_val)]\n",
    "            # violin_data.append(data_filtered.values)\n",
    "            # violin_positions.append(x_position)\n",
    "            # violin_colors.append(color)\n",
    "            \n",
    "            med = data.median()\n",
    "            p10_val = data.quantile(0.10)\n",
    "            q1_val = data.quantile(0.25)\n",
    "            q3_val = data.quantile(0.75)\n",
    "            p90_val = data.quantile(0.90)\n",
    "\n",
    "            ax.errorbar(\n",
    "                x_position, med,\n",
    "                yerr=[[med - q1_val], [q3_val - med]],\n",
    "                fmt=marker, linestyle='none',\n",
    "                markersize=12, color=color,\n",
    "                markerfacecolor='white',\n",
    "                markeredgecolor=color,\n",
    "                markeredgewidth=3,\n",
    "                capsize=8, capthick=2, elinewidth=3, alpha=1, zorder=3\n",
    "            )\n",
    "\n",
    "            # ax.errorbar(\n",
    "            #    x_position, med, \n",
    "            #    yerr=[[med - p10_val], [p90_val - med]],\n",
    "            #    color=color,\n",
    "            #    capsize=4, capthick=1, elinewidth=1.5, alpha=1, zorder=2\n",
    "            # )\n",
    "\n",
    "        x_position += metric_step\n",
    "\n",
    "    x_label_positions.append(group_start + (metric_step * (len(metric_cols)-1)) / 2)\n",
    "    x_labels.append(group_name)\n",
    "    x_position += group_gap\n",
    "\n",
    "# Plot scatter/jitter points (with lower z-order to appear behind errorbars)\n",
    "for scatter in scatter_points:\n",
    "    ax.scatter(scatter['x'], scatter['y'], color=scatter['color'], \n",
    "              alpha=scatter['alpha'], s=12, zorder=1, edgecolors='none')\n",
    "\n",
    "# Legends\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "metric_legend = [\n",
    "    Line2D([0], [0], marker=m, linestyle='none',\n",
    "           markerfacecolor='white', markeredgecolor=c, markeredgewidth=2,\n",
    "           color=c, markersize=10, label=lab)\n",
    "    for m, c, lab in zip(metric_markers, metric_colors, metric_names)\n",
    "]\n",
    "\n",
    "ax.legend(handles=metric_legend, loc='upper left', bbox_to_anchor=(1.02, 0.6),\n",
    "        #   title='Metrics', \n",
    "          framealpha=0)\n",
    "\n",
    "ax.set_ylim(0.3, 1)\n",
    "ax.set_ylabel('$q_K$', fontsize=11)\n",
    "ax.set_yticks([0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "ax.set_yticklabels(['0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1.0'])\n",
    "ax.grid(axis='y', alpha=0.2)\n",
    "ax.spines['left'].set_linewidth(1)\n",
    "ax.spines['bottom'].set_linewidth(1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xticks(x_label_positions)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.margins(x=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.subplots_adjust(right=0.75)\n",
    "# plt.savefig('figures/qk-null-1.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91897708",
   "metadata": {},
   "source": [
    "## Fig 2c-d. POI diversity and income segregation between the three scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd956f0",
   "metadata": {},
   "source": [
    "The below codes provide codes to reproduce the data aggregation procedures from the K-visitation data in the three scenarios to obtain the grid-level metrics used in Fig 2c-d. \n",
    "\n",
    "The calls to the functions are commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d9f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_k_places_for_operation(df, operation):\n",
    "    \"\"\"\n",
    "    Filter K-places by the requested operation.\n",
    "    operation options:\n",
    "        - 'k_freq_only': k_freq == 1 & k_dist != 1\n",
    "        - 'k_dist_only': k_dist == 1 & k_freq != 1\n",
    "        - 'both': k_freq == 1 & k_dist == 1\n",
    "    \"\"\"\n",
    "    freq = df['k_freq'] if 'k_freq' in df.columns else pd.Series(0, index=df.index)\n",
    "    dist = df['k_dist'] if 'k_dist' in df.columns else pd.Series(0, index=df.index)\n",
    "\n",
    "    freq = freq.fillna(0)\n",
    "    dist = dist.fillna(0)\n",
    "\n",
    "    if operation == 'k_freq_only':\n",
    "        mask = (freq == 1) & (dist != 1)\n",
    "    elif operation == 'k_dist_only':\n",
    "        mask = (dist == 1) & (freq != 1)\n",
    "    elif operation == 'both':\n",
    "        mask = (freq == 1) & (dist == 1)\n",
    "    else:\n",
    "        raise ValueError(\"operation must be one of: k_freq_only, k_dist_only, both\")\n",
    "\n",
    "    return df.loc[mask].copy()\n",
    "\n",
    "\n",
    "def aggregate_diversity_and_segregation(df, operation='both'):\n",
    "    \"\"\"\n",
    "    Aggregate POI diversity and visitation segregation by home grid for a K-place selection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Places dataframe with poi_div, visit_inc_seg/visit_inc_seg, k_freq, k_dist, and home_grd_id.\n",
    "    operation : {'k_freq_only', 'k_dist_only', 'both'}\n",
    "        Which K-place filter to apply before aggregation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with aggregated poi_div and segregation metrics per home_grd_id.\n",
    "    \"\"\"\n",
    "    if 'poi_div' not in df.columns:\n",
    "        raise KeyError(\"Expected column 'poi_div' in dataframe.\")\n",
    "\n",
    "    seg_col = 'visit_inc_seg' if 'visit_inc_seg' in df.columns else 'visit_inc_seg'\n",
    "    if seg_col not in df.columns:\n",
    "        raise KeyError(\"Expected segregation column 'visit_inc_seg' or 'visit_inc_seg'.\")\n",
    "\n",
    "    filtered = _filter_k_places_for_operation(df, operation)\n",
    "    if filtered.empty:\n",
    "        return pd.DataFrame(columns=[\n",
    "            'home_grd_id', 'operation', 'n_users', 'n_places',\n",
    "            'poi_div_mean', 'poi_div_median', 'poi_div_std',\n",
    "            'visit_inc_seg_mean', 'visit_inc_seg_median', 'visit_inc_seg_std'\n",
    "        ])\n",
    "    \n",
    "\n",
    "    agg = filtered.groupby('home_grd_id').agg(\n",
    "        poi_div_mean=('poi_div', 'mean'),\n",
    "        poi_div_median=('poi_div', 'median'),\n",
    "        poi_div_p10=('poi_div', lambda x: x.quantile(0.10)),\n",
    "        poi_div_p25=('poi_div', lambda x: x.quantile(0.25)),\n",
    "        poi_div_p75=('poi_div', lambda x: x.quantile(0.75)),\n",
    "        poi_div_p90=('poi_div', lambda x: x.quantile(0.90)),\n",
    "        visit_inc_seg_mean=(seg_col, 'mean'),\n",
    "        visit_inc_seg_median=(seg_col, 'median'),\n",
    "        visit_inc_seg_p10=(seg_col, lambda x: x.quantile(0.10)),\n",
    "        visit_inc_seg_p25=(seg_col, lambda x: x.quantile(0.25)),\n",
    "        visit_inc_seg_p75=(seg_col, lambda x: x.quantile(0.75)),\n",
    "        visit_inc_seg_p90=(seg_col, lambda x: x.quantile(0.90)),\n",
    "        n_places=('user_id', 'size'),\n",
    "        n_users=('user_id', 'nunique')\n",
    "    ).reset_index()\n",
    "\n",
    "    agg.insert(1, 'operation', operation)\n",
    "    cols = ['home_grd_id', 'operation', 'n_users', 'n_places',\n",
    "            'poi_div_mean', 'poi_div_median', 'poi_div_p10', 'poi_div_p25', 'poi_div_p75','poi_div_p90',\n",
    "            'visit_inc_seg_mean', 'visit_inc_seg_median', 'visit_inc_seg_p10','visit_inc_seg_p25','visit_inc_seg_p75','visit_inc_seg_p90'\n",
    "            ]\n",
    "    return agg[cols]\n",
    "\n",
    "\n",
    "def calculate_all_poi_diversity_and_segregation(places_k, places_k_nw, places_k_null):\n",
    "    \"\"\"\n",
    "    Calculate poi_div and visit income segregation for each K-place scheme and operation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict: {dataset_name: {operation: DataFrame, 'combined': DataFrame}}\n",
    "    \"\"\"\n",
    "    datasets = {\n",
    "        'places_k': places_k,\n",
    "        'places_k_nw': places_k_nw,\n",
    "        'places_k_null': places_k_null\n",
    "    }\n",
    "    operations = ['k_freq_only', 'k_dist_only', 'both']\n",
    "\n",
    "    results = {}\n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        results[dataset_name] = {}\n",
    "        combined = []\n",
    "\n",
    "        for op in operations:\n",
    "            agg_df = aggregate_diversity_and_segregation(dataset, operation=op)\n",
    "            results[dataset_name][op] = agg_df\n",
    "            if not agg_df.empty:\n",
    "                combined.append(agg_df)\n",
    "\n",
    "            n_users = int(agg_df['n_users'].sum()) if not agg_df.empty else 0\n",
    "            n_places = int(agg_df['n_places'].sum()) if not agg_df.empty else 0\n",
    "            print(f\"{dataset_name} - {op}: {len(agg_df)} grids, {n_users} users, {n_places} places\")\n",
    "\n",
    "        results[dataset_name]['combined'] = pd.concat(combined, ignore_index=True) if combined else pd.DataFrame()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d43ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Aggregate poi_div and isit_inc_seg for each scenario and dataset\n",
    "# poi_div_seg_results = calculate_all_poi_diversity_and_segregation(\n",
    "#     places_k, places_k_nw, places_k_null\n",
    "# )\n",
    "\n",
    "\n",
    "# # Extract k_freq_only and k_dist_only aggregates per dataset\n",
    "# plot_frames = []\n",
    "# plot_datasets = ['places_k', 'places_k_nw', 'places_k_null']\n",
    "\n",
    "# for dataset in plot_datasets:\n",
    "#     dataset_results = poi_div_seg_results.get(dataset, {})\n",
    "#     freq_df = dataset_results.get('k_freq_only', pd.DataFrame())\n",
    "#     dist_df = dataset_results.get('k_dist_only', pd.DataFrame())\n",
    "\n",
    "#     if freq_df.empty or dist_df.empty:\n",
    "#         print(f\"{dataset}: missing k_freq_only or k_dist_only data; skipping.\")\n",
    "#         continue\n",
    "\n",
    "#     merged = freq_df[['home_grd_id', 'poi_div_mean', 'visit_inc_seg_mean']].merge(\n",
    "#         dist_df[['home_grd_id', 'poi_div_mean', 'visit_inc_seg_mean']],\n",
    "#         on='home_grd_id',\n",
    "#         suffixes=('_k_freq', '_k_dist')\n",
    "#     )\n",
    "\n",
    "#     merged['div_diff'] = merged['poi_div_mean_k_freq'] - merged['poi_div_mean_k_dist']\n",
    "#     merged['seg_diff'] = merged['visit_inc_seg_mean_k_freq'] - merged['visit_inc_seg_mean_k_dist']\n",
    "#     merged['dataset'] = dataset\n",
    "#     plot_frames.append(merged)\n",
    "\n",
    "# poi_seg_plot_df = pd.concat(plot_frames, ignore_index=True) if plot_frames else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_seg_plot_df = pd.read_csv(data_dir / 'poi_seg_diff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1589942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single group (all grids)\n",
    "poi_seg_plot_df['group'] = 'All grids'\n",
    "groups = ['places_k', 'places_k_nw', 'places_k_null']\n",
    "\n",
    "metric_info = [\n",
    "    ('places_k', 'Normal', '#1B8B8B', 'o'),\n",
    "    ('places_k_nw', 'Excl. work', '#E74C3C', 's'),\n",
    "    ('places_k_null', 'Null', '#F39C12', '^'),\n",
    "]\n",
    "\n",
    "group_gap = 0.05\n",
    "metric_step = 0.28\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(5.5, 4), sharey=False, dpi=300)\n",
    "\n",
    "for ax, (metric_col, title) in zip(axes, [('seg_diff', 'Segregation difference'), ('div_diff', 'POI diversity difference')]):\n",
    "    x_position = 0\n",
    "    x_labels = []\n",
    "    x_label_positions = []\n",
    "\n",
    "    for group_name in groups:\n",
    "        group_start = x_position\n",
    "        group_data = poi_seg_plot_df[poi_seg_plot_df['dataset'] == group_name]\n",
    "\n",
    "        for dataset, label, color, marker in metric_info:\n",
    "            data = group_data.loc[group_data['dataset'] == dataset, metric_col].dropna()\n",
    "\n",
    "            if len(data) > 0:\n",
    "                med = data.median()\n",
    "                q1_val = data.quantile(0.25)\n",
    "                q3_val = data.quantile(0.75)\n",
    "\n",
    "                ax.errorbar(\n",
    "                    x_position, med,\n",
    "                    yerr=[[med - q1_val], [q3_val - med]],\n",
    "                    fmt=marker, linestyle='none',\n",
    "                    markersize=10, color=color,\n",
    "                    markerfacecolor='white',\n",
    "                    markeredgecolor=color,\n",
    "                    markeredgewidth=2.5,\n",
    "                    capsize=8, capthick=2, elinewidth=3, alpha=1, zorder=3\n",
    "                )\n",
    "\n",
    "            x_position += metric_step\n",
    "\n",
    "        x_label_positions.append(group_start + (metric_step * (len(metric_info) - 1)) / 2)\n",
    "        x_labels.append(group_name)\n",
    "        x_position += group_gap\n",
    "\n",
    "    if ax is axes[1]:\n",
    "        from matplotlib.lines import Line2D\n",
    "        metric_legend = [\n",
    "            Line2D([0], [0], marker=m, linestyle='none',\n",
    "                   markerfacecolor='white', markeredgecolor=c, markeredgewidth=2,\n",
    "                   color=c, markersize=10, label=lab)\n",
    "            for _, lab, c, m in metric_info\n",
    "        ]\n",
    "        ax.legend(handles=metric_legend, loc='upper left', bbox_to_anchor=(1.02, 0.6),\n",
    "                  framealpha=0)\n",
    "\n",
    "    ax.axhline(0, color='grey', linestyle='--', linewidth=1.5)\n",
    "\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel(' ')\n",
    "    ax.margins(x=0.4)\n",
    "\n",
    "axes[0].set_yticks([-0.1, 0, 0.1])\n",
    "axes[1].set_yticks([-0.2, 0, 0.2, 0.4])\n",
    "axes[0].set_xlabel(r'$\\Delta{Inc. Seg.} (K_{freq} - K_{dist})$', fontsize=11)\n",
    "axes[1].set_xlabel(r'$\\Delta{POI.Div.} (K_{freq} - K_{dist})$', fontsize=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd7e6c",
   "metadata": {},
   "source": [
    "## Fig 3. Spatial distribution of $q_K$ in the four major urban regions in Finland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grid shapefile for mapping\n",
    "grid_df = gpd.read_parquet(data_dir / 'grid_finland.geoparquet')\n",
    "\n",
    "# Merge qk data with grid geometries\n",
    "grid_qk_plot = grid_df.merge(\n",
    "    qk_grid,\n",
    "    on='grd_id',\n",
    "    how='left',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d80ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for Processing and Plotting\n",
    "def prepare_scaled_geometries(gdf, min_size=0.5, max_size=1.3):\n",
    "    \"\"\"\n",
    "    Scale geometries based on POI density bins (log transformed).\n",
    "    Returns a new GeoDataFrame with scaled geometries.\n",
    "    \"\"\"\n",
    "    # Create a copy and ensure index is reset for positional alignment\n",
    "    gdf_scaled = gdf.copy().reset_index(drop=True)\n",
    "    \n",
    "    # Bin-based resizing method parameters\n",
    "    values = [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5]\n",
    "    \n",
    "    # Calculate log POI\n",
    "    poi_sum_log = np.log1p(gdf_scaled['log_poi'].fillna(0))\n",
    "\n",
    "    # Assign each observation to a bin\n",
    "    bin_indices = np.digitize(poi_sum_log, values, right=True)\n",
    "    bin_indices = np.clip(bin_indices, 0, len(values) - 1)\n",
    "\n",
    "    # Create uniform size factors for each bin\n",
    "    n_bins = len(values)\n",
    "    if n_bins > 1:\n",
    "        bin_size_factors = np.linspace(min_size, max_size, n_bins)\n",
    "    else:\n",
    "        bin_size_factors = np.array([1.0])\n",
    "\n",
    "    # Assign size factors\n",
    "    size_factors = bin_size_factors[bin_indices]\n",
    "\n",
    "    # Apply scaling to geometries using list comprehension (faster than iterating rows)\n",
    "    from shapely.affinity import scale\n",
    "    \n",
    "    new_geoms = []\n",
    "    for geom, factor in zip(gdf_scaled['geometry'], size_factors):\n",
    "        if geom is not None:\n",
    "             new_geoms.append(scale(geom, xfact=factor, yfact=factor, origin='centroid'))\n",
    "        else:\n",
    "             new_geoms.append(None)\n",
    "             \n",
    "    gdf_scaled['geometry'] = new_geoms\n",
    "    return gdf_scaled\n",
    "\n",
    "def plot_qk_for_region(gdf, cities, title=None, ax=None):\n",
    "    \"\"\"\n",
    "    Plot qK distribution for a given list of cities on a specific axes.\n",
    "    \"\"\"\n",
    "    # Filter data for the requested cities\n",
    "    plot_data = gdf[gdf['city'].isin(cities)]\n",
    "    \n",
    "    if plot_data.empty:\n",
    "        print(f\"Note: No data found for cities: {cities}\")\n",
    "        return\n",
    "\n",
    "    # Setup plot if ax not provided\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Visual parameters\n",
    "    cmap = load_cmap('miami2')\n",
    "    cut = [0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "    # Plot the scaled grids\n",
    "    plot_data.plot(\n",
    "        column='mean_qk',\n",
    "        cmap=cmap,\n",
    "        scheme='user_defined',\n",
    "        classification_kwds={'bins': cut},\n",
    "        k=5,\n",
    "        alpha=0.7,\n",
    "        legend=True,\n",
    "        ax=ax,\n",
    "        linewidth=1,\n",
    "        edgecolor='white',\n",
    "        legend_kwds={'bbox_to_anchor': (1.05, 1), 'loc': 'upper left'},\n",
    "        zorder=5\n",
    "    )\n",
    "\n",
    "    # Add basemap\n",
    "    ctx.add_basemap(\n",
    "        ax,\n",
    "        crs=gdf.crs.to_string(),\n",
    "        source=ctx.providers.CartoDB.Positron,\n",
    "        alpha=0.7,\n",
    "        attribution=False\n",
    "    )\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "grid_qk_plot = grid_df.merge(\n",
    "    qk_grid,\n",
    "    on='grd_id',\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "# print(\"Scaling geometries based on POI density...\")\n",
    "grid_qk_plot_scaled = prepare_scaled_geometries(grid_qk_plot)\n",
    "\n",
    "# Define regions to plot\n",
    "regions = {\n",
    "    'Helsinki Region': ['Helsinki', 'Espoo', 'Vantaa', 'Kauniainen'],\n",
    "    'Tampere Region': ['Tampere', 'Lempäälä', 'Kangasala', 'Ylöjärvi', 'Nokia'],\n",
    "    'Turku Region': ['Turku', 'Raisio', 'Naantali', 'Kaarina'],\n",
    "    'Oulu Region': ['Oulu', 'Kempele', 'Li']\n",
    "}\n",
    "\n",
    "# Iterate and Plot each region\n",
    "for region_name, city_list in regions.items():\n",
    "    print(f\"Plotting {region_name}...\")\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    plot_qk_for_region(grid_qk_plot_scaled, city_list, title=region_name, ax=ax)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3580da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
